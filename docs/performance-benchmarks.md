# 🚀 vyb-code パフォーマンスベンチマーク

## 概要

このドキュメントは、vyb-code のパフォーマンス特性、特にローカルLLMモデルとGPU加速化の効果について詳細にベンチマーク結果をまとめています。

## テスト環境

### 検証環境 (Windows + WSL2)

- **OS**: Windows + WSL2 (Linux 5.15.133.1-microsoft-standard-WSL2)
- **GPU**: NVIDIA GeForce RTX (12.3GB VRAM)
- **RAM**: 16GB システムメモリ
- **CPU**: WSL2環境での実行

> **注記**: このベンチマークは開発者のWindows + WSL2環境での検証例です。他の環境では結果が異なる場合があります。

### ソフトウェア環境

- **Go**: 1.20.5
- **Docker**: GPU Runtime対応
- **Ollama**: Docker版 (ollama/ollama:latest)
- **NVIDIA Driver**: 560.94
- **CUDA**: 12.6
- **NVIDIA Container Toolkit**: 1.17.8

## ベンチマーク結果

### レスポンス時間比較

| モデル | GPU状態 | レスポンス時間 | GPU メモリ使用量 | 改善率 | 備考 |
|--------|---------|---------------|-----------------|--------|------|
| qwen2.5-coder:3b | CPU | 3.8秒 | N/A | ベースライン | 軽量モデル |
| qwen2.5-coder:14b | CPU | 13.4秒 | N/A | -253% | CPU限界 |
| qwen2.5-coder:14b | **GPU** | **3.2秒** | **10.5GB/12.3GB (85%)** | **+76%** | 最適化 |

### 詳細テスト結果

#### テストケース 1: シンプルなコード生成

- **クエリ**: "Goでシンプルなhello world関数を書いて"
- **qwen2.5-coder:14b (CPU)**: 14.47秒
- **qwen2.5-coder:14b (GPU)**: 3.19秒
- **改善率**: 78%

#### テストケース 2: 複雑なコード分析と提案

- **クエリ**: "vyb-codeプロジェクトにエラーハンドリングを改善したい。現在のコードをanalizeして提案して"
- **qwen2.5-coder:14b (CPU)**: ~13.4秒
- **qwen2.5-coder:14b (GPU)**: 12.86秒
- **改善率**: 4% (複雑なクエリでも安定した高速化)

### リソース使用状況

#### CPU使用率

- **vyb-code プロセス**: <1% (効率的なGo実装)
- **Ollama Docker**: GPU使用時は大幅にCPU負荷減少

#### GPU使用率

- **アイドル時**: 987MiB (8%)
- **14Bモデル実行時**: 10,518MiB (85%)
- **GPU温度**: 45-47°C (安定動作)

#### システムメモリ

- **vyb バイナリ**: ~13MB
- **Docker Ollama**: GPU使用により大幅にRAM使用量削減

## モデル品質比較

### qwen2.5-coder:3b vs qwen2.5-coder:14b

| 項目 | 3B モデル | 14B モデル |
|------|----------|-----------|
| **日本語対応** | 良好 | 優秀 |
| **コード品質** | 基本的 | 高品質・詳細 |
| **説明の詳しさ** | 簡潔 | 包括的 |
| **文脈理解** | 限定的 | 高度 |
| **レスポンス時間** | 3.8秒 | 3.2秒 (GPU) |

### 推奨モデル選択基準

#### qwen2.5-coder:3b 推奨ケース

- **クイック質問**: 簡単な構文確認
- **リソース制限**: GPU非対応環境
- **バッチ処理**: 多数の簡単なクエリ

#### qwen2.5-coder:14b 推奨ケース  

- **複雑なコード生成**: アーキテクチャ設計、リファクタリング
- **詳細な説明**: 教育的なコード解説
- **プロダクション品質**: 実用的なコード作成
- **GPU環境**: 最適なパフォーマンスを要求

## パフォーマンス最適化の要因

### GPU加速化の効果

1. **メモリ帯域幅**: VRAM の高速アクセス (GPU: ~900GB/s vs RAM: ~50GB/s)
2. **並列処理**: 数千のCUDAコアによる行列演算の並列化
3. **専用アーキテクチャ**: AI/ML ワークロード最適化されたハードウェア

### 設定最適化

1. **Docker GPU Runtime**: nvidia-container-toolkit による GPU パススルー
2. **WSL2 GPU Support**: Windows GPU との直接統合
3. **Ollama GPU Detection**: CUDA自動検出とVRAMアロケーション

## 継続的ベンチマーキング

### 定期測定推奨項目

```bash
# パフォーマンス測定
time echo "test query" | ./vyb chat

# GPU使用状況監視  
nvidia-smi --query-gpu=utilization.gpu,memory.used,temperature.gpu --format=csv,noheader,nounits

# メモリ使用量確認
docker stats ollama-vyb-gpu --no-stream

# プロセス監視
htop -p $(pgrep vyb)
```

### ベンチマーク自動化

将来的には以下のテストスイートを検討：

- **レスポンス時間計測**: 様々なクエリタイプでの自動測定
- **リソース使用量プロファイリング**: CPU/GPU/メモリの詳細分析
- **品質評価**: 生成コードの正確性とスタイル一貫性

## 結論

**GPU加速化により vyb-code は Claude Code レベルの実用性を実現:**

- ✅ **3.2秒の高速レスポンス** (Claude Code相当)
- ✅ **高品質な日本語コード生成**
- ✅ **プライバシー完全保護** (ローカル処理)
- ✅ **リソース効率的な動作** (GPU最適化)

これにより、vyb-code はプロダクション環境での日常的なコーディング作業に十分な性能を提供します。
